{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 190,
   "metadata": {
    "id": "GHhNTfWx0AGu",
    "outputId": "3cd883b2-2764-43e0-91ce-b28fb95f9d8f"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The autoreload extension is already loaded. To reload it, use:\n",
      "  %reload_ext autoreload\n"
     ]
    }
   ],
   "source": [
    "# Useful starting lines\n",
    "import numpy as np\n",
    "from helpers import *\n",
    "from methods import *\n",
    "from process_data import *\n",
    "from crossvalidation import *\n",
    "from select_parameter import *\n",
    "\n",
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "\n",
    "seed=20"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 191,
   "metadata": {
    "id": "O86YtohcIdSO",
    "outputId": "4f17ece1-6fd9-4b05-c85d-a7cafdb64839"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[  1,   2,   3,   1,   2,   3,   4,   6,   9,   1,   2,   3,   4,\n",
       "          6,   9,   8,  12,  18,  27,   1,   8,  27],\n",
       "       [  4,   5,   6,  16,  20,  24,  25,  30,  36,  64,  80,  96, 100,\n",
       "        120, 144, 125, 150, 180, 216,  64, 125, 216],\n",
       "       [  6,   7,   8,  36,  42,  48,  49,  56,  64, 216, 252, 288, 294,\n",
       "        336, 384, 343, 392, 448, 512, 216, 343, 512]])"
      ]
     },
     "execution_count": 191,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a=np.array([[1,2,3],[4,5,6],[6,7,8]])\n",
    "a.shape\n",
    "build_poly(a,3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "jJdJ20A-0AG1"
   },
   "source": [
    "# Load the dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 192,
   "metadata": {
    "id": "VNKVzVCh0B2g"
   },
   "outputs": [],
   "source": [
    "from zipfile import ZipFile \n",
    "  \n",
    "# # specifying the zip file name \n",
    "file_name = 'Data/test.csv.zip'\n",
    "  \n",
    "# opening the zip file in READ mode \n",
    "with ZipFile(file_name, 'r') as zip: \n",
    "    zip.extractall('Data/') "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 193,
   "metadata": {
    "id": "dIS5My0U0AG1"
   },
   "outputs": [],
   "source": [
    "y, tX, ids = load_csv_data('Data/train.csv')\n",
    "_, tX_test, ids_test = load_csv_data('Data/test.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 186,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1.98361790e+06 4.70787394e+05 1.52814225e+05 3.51276806e+04\n",
      " 1.81844503e+04 2.23538472e+03 1.83311263e+03 1.26660194e+03\n",
      " 9.44046982e+02 5.19385510e+02 3.84395271e+02 3.74827197e+02\n",
      " 1.78779816e+02 1.38811517e+02 4.57897240e+01 3.98920386e+00\n",
      " 3.49795311e+00 2.74456931e+00 2.45149215e+00 1.65338307e+00\n",
      " 1.40891360e+00 9.95640451e-01 7.46670055e-01]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([[ 1.99836109e+03, -2.10173604e+02,  8.14167196e+01, ...,\n",
       "         2.00564313e+00,  2.88269181e+00, -1.49131148e+00],\n",
       "       [-4.13388223e+02,  1.00498122e+03,  1.06835313e+02, ...,\n",
       "         1.54134907e-01,  4.74176942e-02, -1.47560528e+00],\n",
       "       [-4.79440815e+02,  8.57272034e+02, -1.03988966e+03, ...,\n",
       "        -6.07796561e-01,  1.22248798e+00, -2.87796566e+00],\n",
       "       ...,\n",
       "       [-4.16847076e+02,  9.95937375e+02,  5.32802660e+01, ...,\n",
       "        -1.83859802e-01,  8.12707811e-01, -4.23211088e-01],\n",
       "       [-1.21173594e+03, -5.54246847e+02,  2.96851244e+02, ...,\n",
       "        -1.30280561e-01,  2.23422337e-02, -1.82388641e+00],\n",
       "       [-1.28148740e+03, -6.94469079e+02, -7.86627104e+02, ...,\n",
       "         2.13837124e-01, -5.08304783e-01, -5.43329348e-02]])"
      ]
     },
     "execution_count": 186,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.decomposition import PCA\n",
    "pca = PCA(n_components = 23)\n",
    "pca.fit(tX)\n",
    "X_train_pca = pca.transform(tX)\n",
    "print(pca.explained_variance_)\n",
    "X_train_pca"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "ZwCwFsOGIdSe",
    "outputId": "54cb8c59-8402-486b-cfd6-7bedeca3f354"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "99913 77544 50379 22164\n"
     ]
    }
   ],
   "source": [
    "c1=np.count_nonzero(tX[:,22]==0)\n",
    "c2=np.count_nonzero(tX[:,22]==1)\n",
    "c3=np.count_nonzero(tX[:,22]==2)\n",
    "c4=np.count_nonzero(tX[:,22]==3)\n",
    "\n",
    "print(c1,c2,c3,c4)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "cGxjbAte0AG6"
   },
   "source": [
    "# Methods"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "qhDrrEpc0AG7"
   },
   "source": [
    "## 1. Least Squares with Gradient Descent"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "c-C5gQC_0AG7"
   },
   "source": [
    "#### Cross Validation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "6yMTilRb0AG8",
    "outputId": "2e810048-012d-4944-da60-96ffdeee0a3e"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 - Training accuracy: 0.780448 / Test accuracy : 0.781016\n",
      "1 - Training accuracy: 0.779968 / Test accuracy : 0.778256\n",
      "\n",
      "Average test accuracy: 0.779636\n",
      "Variance test accuracy: 0.000002\n",
      "Min test accuracy: 0.778256\n",
      "Max test accuracy: 0.781016\n"
     ]
    }
   ],
   "source": [
    "# Degree polynomial expansion\n",
    "degrees = [10,10,10,10]\n",
    "\n",
    "# Model parameters\n",
    "max_iters = 5000\n",
    "gamma = 0.005\n",
    "\n",
    "\n",
    "# Split data in k-fold\n",
    "k_fold = 2\n",
    "k_indices = build_k_indices(y, k_fold, seed)\n",
    "\n",
    "\n",
    "accs_train = []\n",
    "accs_test = []\n",
    "\n",
    "for k in range(k_fold):\n",
    "    acc_train, acc_test = cross_validation_least_squares_GD(y, tX, k_indices, k, max_iters, gamma, degrees)\n",
    "    accs_train.append(acc_train)\n",
    "    accs_test.append(acc_test)\n",
    "    \n",
    "for i in range(len(accs_train)):\n",
    "    print(\"%d - Training accuracy: %f / Test accuracy : %f\" % (i, accs_train[i], accs_test[i]))\n",
    "\n",
    "print(\"\\nAverage test accuracy: %f\" % np.mean(accs_test))\n",
    "print(\"Variance test accuracy: %f\" % np.var(accs_test))\n",
    "print(\"Min test accuracy: %f\" % np.min(accs_test))\n",
    "print(\"Max test accuracy: %f\" % np.max(accs_test))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "bkDIXO5f0AHD"
   },
   "source": [
    "## 2. Least Squares with Stochastic Gradient Descent"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "4zHFA3AM0AHE"
   },
   "source": [
    "#### Cross Validation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "qMfrUMhn0AHF"
   },
   "outputs": [],
   "source": [
    "#TO DO\n",
    "\n",
    "initial_w=np.zeros(tX.shape[1])\n",
    "batch_size=1\n",
    "max_iters=1000\n",
    "gamma=0.005\n",
    "\n",
    "loss, weights = least_squares_SGD(y, tX, initial_w, batch_size, max_iters, gamma)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "trL4zoRQ0AHJ"
   },
   "source": [
    "## 3. Least Squares with Normal Equations "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "jcn-b3Ov0AHK"
   },
   "source": [
    "#### Cross Validation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 194,
   "metadata": {
    "id": "ZBfwZaXh0AHL",
    "outputId": "394c5bce-a0d5-4128-90d9-16295bf00a86"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      "1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Riccardo\\Desktop\\1Â° Semester\\Machine Learning\\Projects\\higgs_boson_classification\\process_data.py:116: RuntimeWarning: divide by zero encountered in log\n",
      "  x_test_t2 = np.log(x_test[:, inv_log_cols])\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "Input contains NaN, infinity or a value too large for dtype('float64').",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-194-059b11b6535b>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     16\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0mk\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mk_fold\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     17\u001b[0m     \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mk\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 18\u001b[1;33m     \u001b[0macc_train\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0macc_test\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mcross_validation_least_squares\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0my\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtX\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mk_indices\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mk\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdegrees\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0malpha\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     19\u001b[0m     \u001b[0maccs_train\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0macc_train\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     20\u001b[0m     \u001b[0maccs_test\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0macc_test\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Desktop\\1Â° Semester\\Machine Learning\\Projects\\higgs_boson_classification\\crossvalidation.py\u001b[0m in \u001b[0;36mcross_validation_least_squares\u001b[1;34m(y, x, k_indices, k, degrees, alpha)\u001b[0m\n\u001b[0;32m    168\u001b[0m             \u001b[0mx_train\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mx_test\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mprocess_data\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mx_train\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mx_test\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0malpha\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    169\u001b[0m             \u001b[1;31m# transformation\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 170\u001b[1;33m             \u001b[0mx_train\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mx_test\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mphi\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mx_train\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mx_test\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdegrees\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0midx\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    171\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    172\u001b[0m             \u001b[1;31m# compute weights using given method\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Desktop\\1Â° Semester\\Machine Learning\\Projects\\higgs_boson_classification\\process_data.py\u001b[0m in \u001b[0;36mphi\u001b[1;34m(x_train, x_test, degree)\u001b[0m\n\u001b[0;32m    175\u001b[0m     \u001b[0mpca\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mx_train\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    176\u001b[0m     \u001b[0mx_train\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mpca\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtransform\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mx_train\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 177\u001b[1;33m     \u001b[0mx_test\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mpca\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtransform\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mx_test\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    178\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    179\u001b[0m     \u001b[0mx_train\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0madd_constant_column\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mx_train\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\sklearn\\decomposition\\_base.py\u001b[0m in \u001b[0;36mtransform\u001b[1;34m(self, X)\u001b[0m\n\u001b[0;32m    125\u001b[0m         \u001b[0mcheck_is_fitted\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    126\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 127\u001b[1;33m         \u001b[0mX\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mcheck_array\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    128\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmean_\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    129\u001b[0m             \u001b[0mX\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mX\u001b[0m \u001b[1;33m-\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmean_\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py\u001b[0m in \u001b[0;36minner_f\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m     71\u001b[0m                           FutureWarning)\n\u001b[0;32m     72\u001b[0m         \u001b[0mkwargs\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mupdate\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m{\u001b[0m\u001b[0mk\u001b[0m\u001b[1;33m:\u001b[0m \u001b[0marg\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0mk\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0marg\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mzip\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0msig\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mparameters\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0margs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m}\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 73\u001b[1;33m         \u001b[1;32mreturn\u001b[0m \u001b[0mf\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     74\u001b[0m     \u001b[1;32mreturn\u001b[0m \u001b[0minner_f\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     75\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py\u001b[0m in \u001b[0;36mcheck_array\u001b[1;34m(array, accept_sparse, accept_large_sparse, dtype, order, copy, force_all_finite, ensure_2d, allow_nd, ensure_min_samples, ensure_min_features, estimator)\u001b[0m\n\u001b[0;32m    643\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    644\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mforce_all_finite\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 645\u001b[1;33m             _assert_all_finite(array,\n\u001b[0m\u001b[0;32m    646\u001b[0m                                allow_nan=force_all_finite == 'allow-nan')\n\u001b[0;32m    647\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py\u001b[0m in \u001b[0;36m_assert_all_finite\u001b[1;34m(X, allow_nan, msg_dtype)\u001b[0m\n\u001b[0;32m     95\u001b[0m                 not allow_nan and not np.isfinite(X).all()):\n\u001b[0;32m     96\u001b[0m             \u001b[0mtype_err\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;34m'infinity'\u001b[0m \u001b[1;32mif\u001b[0m \u001b[0mallow_nan\u001b[0m \u001b[1;32melse\u001b[0m \u001b[1;34m'NaN, infinity'\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 97\u001b[1;33m             raise ValueError(\n\u001b[0m\u001b[0;32m     98\u001b[0m                     \u001b[0mmsg_err\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mformat\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     99\u001b[0m                     (type_err,\n",
      "\u001b[1;31mValueError\u001b[0m: Input contains NaN, infinity or a value too large for dtype('float64')."
     ]
    }
   ],
   "source": [
    "# Degree polynomial expansion\n",
    "#degrees = [8,11,9]\n",
    "#degrees = [7,10,9,9]\n",
    "degrees = [5,7,6,6]\n",
    "\n",
    "alpha = 0\n",
    "\n",
    "# Split data in k-fold\n",
    "k_fold = 3\n",
    "k_indices = build_k_indices(y, k_fold, seed)\n",
    "\n",
    "\n",
    "accs_train = []\n",
    "accs_test = []\n",
    "\n",
    "for k in range(k_fold):\n",
    "    print(k)\n",
    "    acc_train, acc_test = cross_validation_least_squares(y, tX, k_indices, k, degrees, alpha)\n",
    "    accs_train.append(acc_train)\n",
    "    accs_test.append(acc_test)\n",
    "    \n",
    "for i in range(len(accs_train)):\n",
    "    print(\"%d - Training accuracy: %f / Test accuracy : %f\" % (i, accs_train[i], accs_test[i]))\n",
    "\n",
    "print(\"\\nAverage test accuracy: %f\" % np.mean(accs_test))\n",
    "print(\"Variance test accuracy: %f\" % np.var(accs_test))\n",
    "print(\"Min test accuracy: %f\" % np.min(accs_test))\n",
    "print(\"Max test accuracy: %f\" % np.max(accs_test))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "xRNkS9Vt0AHP"
   },
   "source": [
    "## 4. Ridge regression with Normal Equations"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "7FSx3D5s0AHQ"
   },
   "source": [
    "#### Lambda"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "nhESWEqZIiET"
   },
   "outputs": [],
   "source": [
    "# Model parameters for least squares\n",
    "#tuning parameters for each category\n",
    "degrees_candidates = [9,10,11,12,13,14]\n",
    "alpha = 0\n",
    "k_fold = 3\n",
    "par_degree, par_lambda, accu = select_parameters_least_squares(y,tX,degrees_candidates,alpha,k_fold,seed)\n",
    "par_degree, accu"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "pbx_ypfVIdS6"
   },
   "outputs": [],
   "source": [
    "# Model parameters for ridge regression\n",
    "#tuning parameters for each category\n",
    "degrees_candidates = [9,10,11,12,13,14]\n",
    "lambdas_candidates = np.logspace(-10, 0, 20)\n",
    "alpha = 0\n",
    "k_fold = 3\n",
    "par_degree, par_lambda, accu = select_parameters_ridge_regression(y,tX,degrees_candidates,lambdas_candidates,alpha,k_fold,seed)\n",
    "par_degree, par_lambda, accu"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "oNtdvgWo0AHW"
   },
   "source": [
    "#### Cross Validation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "2K8LmbWb0AHX",
    "outputId": "33fa584e-49d2-48eb-89fd-6ac9da428a61"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 - Training accuracy: 0.825165 / Test accuracy : 0.818787\n",
      "1 - Training accuracy: 0.835869 / Test accuracy : 0.831627\n",
      "2 - Training accuracy: 0.838593 / Test accuracy : 0.831351\n",
      "\n",
      "Average test accuracy: 0.827255\n",
      "Variance test accuracy: 0.000036\n",
      "Min test accuracy: 0.818787\n",
      "Max test accuracy: 0.831627\n"
     ]
    }
   ],
   "source": [
    "# Process data parameters\n",
    "#degrees = [8,11,10,10]\n",
    "degrees = [7,10,9,9]\n",
    "alpha = 1\n",
    "\n",
    "# Model parameters\n",
    "lambdas = [0,0,0,0]\n",
    "\n",
    "# Split data in k-fold\n",
    "k_fold = 3\n",
    "k_indices = build_k_indices(y, k_fold, seed)\n",
    "\n",
    "\n",
    "accs_train = []\n",
    "accs_test = []\n",
    "\n",
    "for k in range(k_fold):\n",
    "    acc_train, acc_test = cross_validation_ridge_regression(y, tX, k_indices, k, lambdas, degrees, alpha)\n",
    "    accs_train.append(acc_train)\n",
    "    accs_test.append(acc_test)\n",
    "    \n",
    "for i in range(len(accs_train)):\n",
    "    print(\"%d - Training accuracy: %f / Test accuracy : %f\" % (i, accs_train[i], accs_test[i]))\n",
    "\n",
    "print(\"\\nAverage test accuracy: %f\" % np.mean(accs_test))\n",
    "print(\"Variance test accuracy: %f\" % np.var(accs_test))\n",
    "print(\"Min test accuracy: %f\" % np.min(accs_test))\n",
    "print(\"Max test accuracy: %f\" % np.max(accs_test))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "D0qlFWFL0AHb"
   },
   "source": [
    "## 5. Logistic Regression with Stochastic Gradient Descent\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "0uYY_UbE0AHc"
   },
   "source": [
    "#### Cross Validation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "tqdp4-eb0AHc",
    "outputId": "5eba52c4-27c6-461c-9865-61aadde2bd6d"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "7.997182550126146 0 /5000\n",
      "0.7524469806959074 1000 /5000\n",
      "0.4363734465688057 2000 /5000\n",
      "0.400023839876429 3000 /5000\n",
      "0.40076385746875537 4000 /5000\n",
      "10.371044956652037 0 /5000\n",
      "1.5550707519015254 1000 /5000\n",
      "0.661663323193932 2000 /5000\n",
      "0.5936779549816508 3000 /5000\n",
      "0.5260682969312651 4000 /5000\n",
      "8.442467521375363 0 /5000\n",
      "1.7929335626679517 1000 /5000\n",
      "0.7223707415043099 2000 /5000\n",
      "0.5914451124506169 3000 /5000\n",
      "0.5454690010169485 4000 /5000\n",
      "12.029170671306018 0 /5000\n",
      "2.0525746152729285 1000 /5000\n",
      "0.8818547205280977 2000 /5000\n",
      "0.6671236655053144 3000 /5000\n",
      "0.5709404738188759 4000 /5000\n",
      "6.689309726685983 0 /5000\n",
      "0.7984062586900572 1000 /5000\n",
      "0.4669079564079578 2000 /5000\n",
      "0.4200246548981903 3000 /5000\n",
      "0.4292098025507569 4000 /5000\n",
      "9.748515728107092 0 /5000\n",
      "1.2804452477863466 1000 /5000\n",
      "0.6366004683073873 2000 /5000\n",
      "0.5702327086476892 3000 /5000\n",
      "0.5406348712757687 4000 /5000\n",
      "10.207457083659229 0 /5000\n",
      "1.8709968020623324 1000 /5000\n",
      "0.8871537214879525 2000 /5000\n",
      "0.6549933484898737 3000 /5000\n",
      "0.6273568446088855 4000 /5000\n",
      "10.921340377430047 0 /5000\n",
      "2.2292933821924934 1000 /5000\n",
      "0.8149678070962392 2000 /5000\n",
      "0.6580696579333538 3000 /5000\n",
      "0.606312214919163 4000 /5000\n",
      "0 - Training accuracy: 0.781112 / Test accuracy : 0.782488\n",
      "1 - Training accuracy: 0.781568 / Test accuracy : 0.778112\n",
      "\n",
      "Average test accuracy: 0.780300\n",
      "Variance test accuracy: 0.000005\n",
      "Min test accuracy: 0.778112\n",
      "Max test accuracy: 0.782488\n"
     ]
    }
   ],
   "source": [
    "# Degree polynomial expansion\n",
    "degrees = [7,10,9,9]\n",
    "\n",
    "# Model parameters\n",
    "max_iters = 5000\n",
    "gamma = 0.005\n",
    "batch_size = 1\n",
    "\n",
    "# Split data in k-fold\n",
    "k_fold = 2\n",
    "k_indices = build_k_indices(y, k_fold, seed)\n",
    "\n",
    "\n",
    "accs_train = []\n",
    "accs_test = []\n",
    "\n",
    "for k in range(k_fold):\n",
    "    acc_train, acc_test = cross_validation(y, tX, logistic_regression, k_indices, k, batch_size=batch_size, \n",
    "                                           max_iters=max_iters, gamma=gamma, degrees=degrees)\n",
    "    accs_train.append(acc_train)\n",
    "    accs_test.append(acc_test)\n",
    "    \n",
    "for i in range(len(accs_train)):\n",
    "    print(\"%d - Training accuracy: %f / Test accuracy : %f\" % (i, accs_train[i], accs_test[i]))\n",
    "\n",
    "print(\"\\nAverage test accuracy: %f\" % np.mean(accs_test))\n",
    "print(\"Variance test accuracy: %f\" % np.var(accs_test))\n",
    "print(\"Min test accuracy: %f\" % np.min(accs_test))\n",
    "print(\"Max test accuracy: %f\" % np.max(accs_test))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "nGOLWOaT0AHg"
   },
   "source": [
    "## 6. Regularized Logistic Regression with Stochastic Gradient Descent"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "fyOb7sDh0AHh"
   },
   "source": [
    "#### Optimal Lambda"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "iy2RbgfS0AHh"
   },
   "outputs": [],
   "source": [
    "# TO DO"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "WjGmRlLe0AHm"
   },
   "source": [
    "#### Cross Validation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "Nj7QHy7E0AHn"
   },
   "outputs": [],
   "source": [
    "# TO DO\n",
    "\n",
    "lambda_ = 0.001\n",
    "initial_w = np.random.random(tX.shape[1])\n",
    "batch_size = 1\n",
    "max_iters = 1000\n",
    "gamma = 0.1\n",
    "\n",
    "loss, weights = reg_logistic_regression(y, tX, lambda_, initial_w, batch_size,  max_iters, gamma)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "wPuY4BlP0AHr"
   },
   "source": [
    "# Prediction (file.run)\n",
    "by now the best accuracy predicted is through RIDGE REGRESSION"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 176,
   "metadata": {
    "id": "8zP-dXnh0AHr"
   },
   "outputs": [],
   "source": [
    "# Split data in subsets corresponding to a jet value\n",
    "msks_jet_train = get_jet_masks(tX)\n",
    "msks_jet_test = get_jet_masks(tX_test)\n",
    "\n",
    "# Degree polynomial expansion\n",
    "degrees = [5,7,6,6]\n",
    "alpha = 0\n",
    "# Ridge regression parameters for each subset\n",
    "lambdas = [0,0,0,0]\n",
    "\n",
    "# Vector to store the final prediction\n",
    "y_pred = np.zeros(tX_test.shape[0])\n",
    "\n",
    "for idx in range(len(msks_jet_train)):\n",
    "    x_train = tX[msks_jet_train[idx]]\n",
    "    x_test = tX_test[msks_jet_test[idx]]\n",
    "    y_train = y[msks_jet_train[idx]]\n",
    "\n",
    "    # Pre-processing of data\n",
    "    x_train, x_test = process_data(x_train, x_test, alpha)\n",
    "    x_train, x_test = phi(x_train, x_test, degrees[idx])\n",
    "\n",
    "    loss, weights = ridge_regression(y_train, x_train, lambdas[idx])\n",
    "\n",
    "    y_test_pred = predict_labels(weights, x_test)\n",
    "\n",
    "    y_pred[msks_jet_test[idx]] = y_test_pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 177,
   "metadata": {
    "id": "caDm4rbc0AHx",
    "outputId": "3d109399-41cf-4a15-b840-a10ef1eecf00"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "From 568238 test examples, 181823 are 1, i.e. the 0.31997684068999255 %\n"
     ]
    }
   ],
   "source": [
    "higgs = np.count_nonzero(y_pred==1)\n",
    "print(f'From {y_pred.shape[0]} test examples, {higgs} are 1, i.e. the {higgs/y_pred.shape[0]} %')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Mfjj7aBa0AH5"
   },
   "source": [
    "#### Generate predictions and save ouput in csv format for submission"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 178,
   "metadata": {
    "id": "Ub5ITgmg0AH5"
   },
   "outputs": [],
   "source": [
    "OUTPUT_PATH = 'data/leastSquares.csv' \n",
    "create_csv_submission(ids_test, y_pred, OUTPUT_PATH)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "SuQONAGy0AH9"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "8_3W_bxL0AIA"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "fs6Nkx-q0AIE"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "KoefpFkD0AIH"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "eJimq_Yz0AIL"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "yfJHyeRX0AIO"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "xCbdi7wq0AIR"
   },
   "source": [
    "# OTHERS (old)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "PXTtZSbs0AIS"
   },
   "source": [
    "### Umbalanced Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "2GimxSef0AIS"
   },
   "outputs": [],
   "source": [
    "higgs = np.count_nonzero(y==1)\n",
    "print(f'From {y.shape[0]} training examples, {higgs} are 1, i.e. the {higgs/y.shape[0]} %')\n",
    "\n",
    "# Random Over Sampling\n",
    "#tX, y = Random_Over_Sampling(tX, y)\n",
    "\n",
    "#higgs = np.count_nonzero(y==1)\n",
    "#print(f'Applying Random Over Sampling: \\nFrom {y.shape[0]} training examples, {higgs} are 1, i.e. the {higgs/y.shape[0]} %')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "a3hPd3D80AIX"
   },
   "source": [
    "# Preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "1KoJPkg50AIY"
   },
   "outputs": [],
   "source": [
    "tX, tX_test = process_data(tX, tX_test, add_constant_col=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Yx3zjeX60AIe"
   },
   "source": [
    "# Cross Validation\n",
    "IDEA: insert CV in each of the methods above"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "QFR2Y75w0AIf"
   },
   "outputs": [],
   "source": [
    "def cross_validation(y, x, k_indices, k, regression_method, **args):\n",
    "    \"\"\"\n",
    "    Completes k-fold cross-validation using the regression method\n",
    "    passed as argument.\n",
    "    \"\"\"\n",
    "    # get k'th subgroup in test, others in train\n",
    "    msk_test = k_indices[k]\n",
    "    msk_train = np.delete(k_indices, (k), axis=0).ravel()\n",
    "\n",
    "    x_train = x[msk_train, :]\n",
    "    x_test = x[msk_test, :]\n",
    "    y_train = y[msk_train]\n",
    "    y_test = y[msk_test]\n",
    "\n",
    "    # data pre-processing\n",
    "    #x_train, x_test = process_data(x_train, x_test, True)\n",
    "\n",
    "    # compute weights using given method\n",
    "    loss, weights = regression_method(y=y_train, tx=x_train, **args)\n",
    "    \n",
    "    # predict output for train and test data\n",
    "    y_train_pred = predict_labels(weights, x_train)\n",
    "    y_test_pred = predict_labels(weights, x_test)\n",
    "    \n",
    "    \n",
    "    # compute accuracy for train and test data\n",
    "    acc_train = compute_accuracy(y_train_pred, y_train)\n",
    "    acc_test = compute_accuracy(y_test_pred, y_test)\n",
    "\n",
    "    return acc_train, acc_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "bSzxeArR0AIj",
    "outputId": "7efa3077-566c-45a4-d95b-d51c538dd74c"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 - Training accuracy: 0.775480 / Test accuracy : 0.776096\n",
      "1 - Training accuracy: 0.775888 / Test accuracy : 0.774656\n",
      "\n",
      "Average test accuracy: 0.775376\n",
      "Variance test accuracy: 0.000001\n",
      "Min test accuracy: 0.774656\n",
      "Max test accuracy: 0.776096\n"
     ]
    }
   ],
   "source": [
    "regression_method = ridge_regression\n",
    "\n",
    "# Model parameters\n",
    "lambda_ = 0.0005\n",
    "\n",
    "# Split data in k-fold\n",
    "k_fold = 2\n",
    "k_indices = build_k_indices(y, k_fold, seed)\n",
    "\n",
    "\n",
    "accs_train = []\n",
    "accs_test = []\n",
    "\n",
    "for k in range(k_fold):\n",
    "    acc_train, acc_test = cross_validation(y, tX, k_indices, k, regression_method, lambda_=lambda_)\n",
    "    accs_train.append(acc_train)\n",
    "    accs_test.append(acc_test)\n",
    "    \n",
    "for i in range(len(accs_train)):\n",
    "    print(\"%d - Training accuracy: %f / Test accuracy : %f\" % (i, accs_train[i], accs_test[i]))\n",
    "\n",
    "print(\"\\nAverage test accuracy: %f\" % np.mean(accs_test))\n",
    "print(\"Variance test accuracy: %f\" % np.var(accs_test))\n",
    "print(\"Min test accuracy: %f\" % np.min(accs_test))\n",
    "print(\"Max test accuracy: %f\" % np.max(accs_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "CUHb8uzq0AHR"
   },
   "outputs": [],
   "source": [
    "# TO CHECK\n",
    "\n",
    "# To evaluate the best lambda that minimizes the test error\n",
    "loss, weights, best_lambda = cross_validation_ridge_regression(y,tX)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "97-LOyA10AIp"
   },
   "outputs": [],
   "source": [
    "# Only for non logistic methods\n",
    "y_pred = predict_labels(weights, tX_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "M8VXKujj0AIw"
   },
   "outputs": [],
   "source": [
    "# Only for Logistic methods\n",
    "y_pred = sigmoid(tX_test@weights)\n",
    "y_pred[y_pred <0.5] = -1\n",
    "y_pred[y_pred > 0.5] = 1"
   ]
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "colab": {
   "collapsed_sections": [],
   "name": "main.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
