{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Useful starting lines\n",
    "import numpy as np\n",
    "from matplotlib import pyplot as plt    \n",
    "from helpers import *\n",
    "from methods import *\n",
    "from process_data import *\n",
    "from crossValidation import *\n",
    "from exploration import *\n",
    "\n",
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "\n",
    "seed=20"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Exploratory Analysis\n",
    "In this first part we explore our sample set, by first concatenating the training and test set to have a global view on our problem. Then we plot for each features the samples, and we will identify the eventual outliers."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from zipfile import ZipFile \n",
    "  \n",
    "# # specifying the zip file name \n",
    "file_name = 'Data/test.csv.zip'\n",
    "  \n",
    "# opening the zip file in READ mode \n",
    "with ZipFile(file_name, 'r') as zip: \n",
    "    zip.extractall('Data/') \n",
    "\n",
    "y_train, tX_train, ids = load_csv_data('Data/train.csv')\n",
    "_, tX_test, ids_test = load_csv_data('Data/test.csv')\n",
    "featuresNames = np.genfromtxt('Data/train.csv', delimiter=\",\", dtype=str,max_rows=1)[2:-1]\n",
    "\n",
    "tX = np.r_[tX_train,tX_test]"
   ]
  },
  {
   "source": [
    "## Variance Analysis\n",
    "We may study the variance of each features. We can do the following assumption, a feature with a low variance may indicate that the feature is not rich enough to contribute to the model. Hence we may later consider removing this feature. Low variance features:\n",
    "* 7/28 DER_deltar_tau_lep: 0.6097662799238968\n",
    "* 10/28 DER_pt_ratio_lep_tau: 0.714209748113439\n",
    "* 14/28 PRI_tau_eta: 1.472609701754366\n",
    "* 17/28 PRI_lep_eta: 1.5983290031447774\n",
    "\n"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "source": [
    "featuresVariance(tX,featuresNames)"
   ],
   "cell_type": "code",
   "metadata": {},
   "execution_count": null,
   "outputs": []
  },
  {
   "source": [
    "## Distribution Analysis\n",
    "*Be aware of the column number!*\n",
    "Now we can study the distribution of each feature given the label. If the distributions given two different labels are close and similar enoguh, it means that the feature may not be contributing enough to the classification problem. From the plots we may consider the following low separation features:\n",
    "* 8/28 DER_pt_tot\n",
    "* 16/28 PRI_lep_pt\n",
    "* 26/28 PRI_jet_subleading_pt"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "distributionsPlot(y_train,tX_train,featuresNames)"
   ]
  },
  {
   "source": [
    "## Outlier Analysis"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "featuresPlot(tX,featuresNames)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6-final"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}